{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsauravsharma/insincere-question-classification/blob/bishal/Lstm%2Bcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERwz8_SQE3cg",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "25b45e27-0920-4b07-a26f-0bd31025a2ff"
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2c37ee7e-dba5-46ff-87d1-b9116e140ce9\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2c37ee7e-dba5-46ff-87d1-b9116e140ce9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"bishalgaire360\",\"key\":\"69b39489849cd899eaa93339bad30cdb\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AN8twG_FBBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "75149c23-413c-480f-f179-639d8441beaa"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c quora-insincere-questions-classification\n",
        "from zipfile import ZipFile\n",
        "file_name=\"train.csv.zip\"\n",
        "#file_name=\"embeddings.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')\n",
        "file_name=\"embeddings.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "df=pd.read_csv('train.csv')\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "emb_file = \"glove.840B.300d/glove.840B.300d.txt\"\n",
        "#emb_file =\"GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
        "glove_dic = {}\n",
        "for line in tqdm_notebook(open(emb_file)):\n",
        "    temp = line.split(\" \")\n",
        "    glove_dic[temp[0]] = np.asarray(temp[1:],dtype='float32')\n",
        "def clean_text(x):\n",
        "\n",
        "    x = str(x)\n",
        "    for punct in \"/-'\":\n",
        "        x = x.replace(punct, ' ')\n",
        "    for punct in '&':\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
        "        x = x.replace(punct, '')\n",
        "    return x\n",
        "df[\"question_text\"] = df[\"question_text\"].progress_apply(lambda x: clean_text(x))\n",
        "del df['qid']\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "n_words = 50000\n",
        "tokenizer = Tokenizer(num_words=n_words)\n",
        "tokenizer.fit_on_texts(list(train.question_text))\n",
        "\n",
        "q_train = tokenizer.texts_to_sequences(train.question_text)\n",
        "q_val = tokenizer.texts_to_sequences(val.question_text)\n",
        "#q_test = tokenizer.texts_to_sequences(df_test.question_text)\n",
        "\n",
        "max_len = 100\n",
        "q_train = pad_sequences(q_train,maxlen=max_len)\n",
        "q_val = pad_sequences(q_val,maxlen=max_len)\n",
        "#q_test = pad_sequences(q_test,maxlen=max_len)\n",
        "\n",
        "y_train = train.target\n",
        "y_val = val.target\n",
        "\n",
        "del train,val,df\n",
        "word_index = tokenizer.word_index\n",
        "emb_size = glove_dic['.'].shape[0]\n",
        "emb_matrix = np.zeros((n_words,emb_size))\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        continue\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        emb_matrix[index,:] = vec\n",
        "train, val = train_test_split(df, test_size=0.1, random_state=42)\n",
        "n_words = 50000\n",
        "tokenizer = Tokenizer(num_words=n_words)\n",
        "tokenizer.fit_on_texts(list(train.question_text))\n",
        "\n",
        "q_train = tokenizer.texts_to_sequences(train.question_text)\n",
        "q_val = tokenizer.texts_to_sequences(val.question_text)\n",
        "#q_test = tokenizer.texts_to_sequences(df_test.question_text)\n",
        "\n",
        "max_len = 100\n",
        "q_train = pad_sequences(q_train,maxlen=max_len)\n",
        "q_val = pad_sequences(q_val,maxlen=max_len)\n",
        "#q_test = pad_sequences(q_test,maxlen=max_len)\n",
        "\n",
        "y_train = train.target\n",
        "y_val = val.target\n",
        "\n",
        "del train,val\n",
        "word_index = tokenizer.word_index\n",
        "emb_size = glove_dic['.'].shape[0]\n",
        "emb_matrix = np.zeros((n_words,emb_size))\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        continue\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        emb_matrix[index,:] = vec\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "embeddings.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98feb6856a6448ffa70cec7aa2a022ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 3251/1306122 [00:00<00:40, 32509.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:15<00:00, 84486.89it/s]\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d9f94afd43f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mn_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mq_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry4G4l8qO0_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "#find the best threshold\n",
        "def optim_thres(y_val,y_pred):\n",
        "    score = 0\n",
        "    thresholds = np.arange(0.1,0.501,0.01)\n",
        "    for thres in thresholds:\n",
        "        thres = np.round(thres,2)\n",
        "        temp_pred = (y_pred > thres).astype(int)\n",
        "        temp_score = f1_score(y_val,temp_pred)\n",
        "        print(\"Thres: {} --------- F1: {}\".format(thres,temp_score))\n",
        "        if temp_score > score:\n",
        "            score = temp_score\n",
        "            final_thres = thres\n",
        "    return final_thres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2neABH8i4vv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import initializers, regularizers, constraints\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "        \n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        \n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYGDcmpso1ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "b33391d6-6684-479f-bb07-b6bb5c02c810"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import LSTM,Bidirectional,TimeDistributed, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout,Conv1D\n",
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding,Flatten,Dense\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "#x = Attention(step_dim=max_len)(x)\n",
        "#model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "#model.add(layers.GlobalMaxPooling1D())\n",
        "x=Conv1D(128,5,activation='relu')(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(128,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_19 (Embedding)     (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 100, 200)          321600    \n",
            "_________________________________________________________________\n",
            "conv1d_12 (Conv1D)           (None, 96, 128)           128128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 15,466,369\n",
            "Trainable params: 15,466,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYVSItCUFqXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "8b6aeea0-cd35-429c-d985-b0dad3af7d52"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding,Flatten,Dense\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "\n",
        "\n",
        "max_len = 100\n",
        "#Attention(step_dim=max_len)(x)\n",
        "model = Sequential()\n",
        "model.add(layers.Embedding(input_dim=n_words, \n",
        "                           output_dim=emb_size, \n",
        "                           input_length=max_len,\n",
        "                           weights=[emb_matrix]))\n",
        "#model.add\n",
        "#model.add(Attention(step_dim=max_len))\n",
        "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(10, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy',f1])\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 100, 300)          15000000  \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 96, 128)           192128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 15,193,429\n",
            "Trainable params: 15,193,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12mn4wpNK4C-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761
        },
        "outputId": "e5574d01-c5bd-49e3-9e41-849e1c633b6d"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n",
        "                     validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 112s 95us/step - loss: 0.1157 - acc: 0.9535 - f1: 0.5155 - val_loss: 0.1017 - val_acc: 0.9594 - val_f1: 0.6277\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.62771, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 108s 92us/step - loss: 0.0982 - acc: 0.9607 - f1: 0.6484 - val_loss: 0.0992 - val_acc: 0.9599 - val_f1: 0.6362\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.62771 to 0.63621, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 109s 92us/step - loss: 0.0888 - acc: 0.9646 - f1: 0.6903 - val_loss: 0.0997 - val_acc: 0.9597 - val_f1: 0.6514\n",
            "\n",
            "Epoch 00003: val_f1 improved from 0.63621 to 0.65136, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 108s 92us/step - loss: 0.0794 - acc: 0.9685 - f1: 0.7299 - val_loss: 0.1021 - val_acc: 0.9598 - val_f1: 0.6484\n",
            "\n",
            "Epoch 00004: val_f1 did not improve from 0.65136\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 109s 92us/step - loss: 0.0694 - acc: 0.9729 - f1: 0.7700 - val_loss: 0.1074 - val_acc: 0.9573 - val_f1: 0.6420\n",
            "\n",
            "Epoch 00005: val_f1 did not improve from 0.65136\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 108s 92us/step - loss: 0.0590 - acc: 0.9775 - f1: 0.8121 - val_loss: 0.1199 - val_acc: 0.9573 - val_f1: 0.6150\n",
            "\n",
            "Epoch 00006: val_f1 did not improve from 0.65136\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 108s 92us/step - loss: 0.0494 - acc: 0.9816 - f1: 0.8482 - val_loss: 0.1317 - val_acc: 0.9554 - val_f1: 0.6245\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.65136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-547922ee9683>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n\u001b[1;32m      9\u001b[0m                      validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWeb3itkLds_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1a1f11e2-f4d4-478c-ea31-ebde347fd545"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['f1'])\n",
        "plt.plot(history.history['val_f1'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('F1')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmHpZWBhjjKmXhYUxxph6/X91N0FEgWIQAgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQrm8NVAgdB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}