{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn,lstm gru with preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsauravsharma/insincere-question-classification/blob/bishal/cnn%2Clstm_gru_with_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3S9ilUs8n0I",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "97f08300-aa00-4854-9bd6-065656108a20"
      },
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.3.9)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f434f671-7f8c-4195-b02e-0f2c1dcdfc99\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f434f671-7f8c-4195-b02e-0f2c1dcdfc99\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (4).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"bishalgaire360\",\"key\":\"69b39489849cd899eaa93339bad30cdb\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31aOt3vT8yb8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a3b30d22-2028-4cc5-dcb0-7bd29ca7126f"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c quora-insincere-questions-classification\n",
        "from zipfile import ZipFile\n",
        "file_name=\"train.csv.zip\"\n",
        "#file_name=\"embeddings.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')\n",
        "file_name=\"embeddings.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "df=pd.read_csv('train.csv')\n",
        "from tqdm import tqdm_notebook\n",
        "import numpy as np\n",
        "emb_file = \"glove.840B.300d/glove.840B.300d.txt\"\n",
        "#emb_file =\"GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\n",
        "glove_dic = {}\n",
        "for line in tqdm_notebook(open(emb_file)):\n",
        "    temp = line.split(\" \")\n",
        "    glove_dic[temp[0]] = np.asarray(temp[1:],dtype='float32')\n",
        "\n",
        "del df['qid']\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "embeddings.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "sample_submission.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67c0b6612e644c219e8dd89c164adbdd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frR72AyV85Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "\n",
        "def clean_misspell(text):\n",
        "    \"\"\"\n",
        "    misspell list (quora vs. glove)\n",
        "    \"\"\"\n",
        "    misspell_to_sub = {\n",
        "        '(T|t)erroristan': 'terrorist Pakistan',\n",
        "        'BIMARU': 'Bihar, Madhya Pradesh, Rajasthan, Uttar Pradesh',\n",
        "        '(H|h)induphobic': 'Hindu phobic',\n",
        "        '(H|h)induphobia': 'Hindu phobic',\n",
        "        'Babchenko': 'Arkady Arkadyevich Babchenko faked death',\n",
        "        'Boshniaks': 'Bosniaks',\n",
        "        'Dravidanadu': 'Dravida Nadu',\n",
        "        'mysoginists': 'misogynists',\n",
        "        'MGTOWS': 'Men Going Their Own Way',\n",
        "        'mongloid': 'Mongoloid',\n",
        "        'unsincere': 'insincere',\n",
        "        'meninism': 'male feminism',\n",
        "        'jewplicate': 'jewish replicate',\n",
        "        'unoin': 'Union',\n",
        "        'daesh': 'Islamic State of Iraq and the Levant',\n",
        "        'Kalergi': 'Coudenhove-Kalergi',\n",
        "        ' apist': ' Ape',\n",
        "        '(B|b)hakts': 'Bhakt',\n",
        "        'Tambrahms': 'Tamil Brahmin',\n",
        "        'Pahul': 'Amrit Sanskar',\n",
        "        'SJW(s|)': 'social justice warrior',\n",
        "        'incel(s|)': 'involuntary celibates',\n",
        "        'emiratis': 'Emiratis',\n",
        "        'weatern': 'western',\n",
        "        'Pizzagate': 'Pizzagate conspiracy theory',\n",
        "        'naïve': 'naive',\n",
        "        'Skripal': 'Sergei Skripal',\n",
        "        '(R|r)emainers': 'remainer',\n",
        "        'antibrahmin': 'anti Brahminism',\n",
        "        'HYPSM': ' Harvard, Yale, Princeton, Stanford, MIT',\n",
        "        'HYPS': ' Harvard, Yale, Princeton, Stanford',\n",
        "        'kompromat': 'compromising material',\n",
        "        '(T|t)harki': 'pervert',\n",
        "        'mastuburate': 'masturbate',\n",
        "        'Zoë': 'Zoe',\n",
        "        'indans': 'Indian',\n",
        "        'xender': 'gender',\n",
        "        'Naxali': 'Naxalite',\n",
        "        'Bathla': 'Namit Bathla',\n",
        "        'Mewani': 'Indian politician Jignesh Mevani',\n",
        "        'clichéd': 'cliché',\n",
        "        'cliché(s|)': 'cliché',\n",
        "        'Wjy': 'Why',\n",
        "        'Fadnavis': 'Indian politician Devendra Fadnavis',\n",
        "        'Awadesh': 'Indian engineer Awdhesh Singh',\n",
        "        'Awdhesh': 'Indian engineer Awdhesh Singh',\n",
        "        'Khalistanis': 'Sikh separatist movement',\n",
        "        'madheshi': 'Madheshi',\n",
        "        'Quorans': 'Quoran',\n",
        "        'BNBR': 'Be Nice, Be Respectful',\n",
        "        'Bolsonaro': 'Jair Bolsonaro',\n",
        "        'XXXTentacion': 'Tentacion',\n",
        "        'Padmavat': 'Indian Movie Padmaavat',\n",
        "        'Žižek': 'Slovenian philosopher Slavoj Žižek',\n",
        "        'Adityanath': 'Indian monk Yogi Adityanath',\n",
        "        '(B|b)rexit': 'British Exit',\n",
        "        'jallikattu': 'Jallikattu',\n",
        "        'fortnite': 'Fortnite',\n",
        "        'Swachh': 'Swachh Bharat mission campaign',\n",
        "        'Qoura': 'Quora',\n",
        "        'narcissit': 'narcissist',\n",
        "        # extra in sample\n",
        "        'Doklam': 'Tibet',\n",
        "        'Drumpf': 'Donald Trump',\n",
        "        'Strzok': 'Hillary Clinton scandal',\n",
        "        'rohingya': 'Rohingya',\n",
        "        'wumao': 'offensive Chinese',\n",
        "        'Sanghis': 'Sanghi',\n",
        "        'Tamilans': 'Tamils',\n",
        "        'biharis': 'Biharis',\n",
        "        'Rejuvalex': 'hair growth formula',\n",
        "        'Feku': 'The Man of India',\n",
        "        'deplorables': 'deplorable',\n",
        "        'muhajirs': 'Muslim immigrants',\n",
        "        'Brexiters': 'British Exit supporters',\n",
        "        'Brexiteers': 'British Exit supporters',\n",
        "        'Brexiting': 'British Exit',\n",
        "        'Gujratis': 'Gujarati',\n",
        "        'Chutiya': 'Tibet people',\n",
        "        'thighing': 'masturbate',\n",
        "        '卐': 'Nazi Germany',\n",
        "        'rohingyas': 'Muslim ethnic group',\n",
        "        'Pribumi': 'Native Indonesians',\n",
        "        'Gurmehar': 'Gurmehar Kaur Indian student activist',\n",
        "        'Novichok': 'Soviet Union agents',\n",
        "        'Khazari': 'Khazars',\n",
        "        'Demonetization': 'demonetization',\n",
        "        'demonetisation': 'demonetization',\n",
        "        'cryptocurrencies': 'bitcoin',\n",
        "        'Hindians': 'offensive Indian',\n",
        "        'vaxxers': 'vocal nationalists',\n",
        "        'remoaners': 'remainer',\n",
        "        'Jewism': 'Judaism',\n",
        "        'Eroupian': 'European',\n",
        "        'WMAF': 'White male Asian female',\n",
        "        'moeslim': 'Muslim',\n",
        "        'cishet': 'cisgender and heterosexual person',\n",
        "        'Eurocentrics': 'Eurocentrism',\n",
        "        'Jewdar': 'Jew dar',\n",
        "        'Asifas': 'abduction, rape, murder case',\n",
        "        'marathis': 'Marathi',\n",
        "        'Trumpanzees': 'Trump chimpanzee',\n",
        "        'quoras': 'Quora',\n",
        "        'Crimeans': 'Crimea people',\n",
        "        'atrracted': 'attract',\n",
        "        'LGBT': 'lesbian, gay, bisexual, transgender',\n",
        "        'Boshniaks': 'Bosniaks',\n",
        "        'Myeshia': 'widow of Green Beret killed in Niger',\n",
        "        'demcoratic': 'Democratic',\n",
        "        'raaping': 'rape',\n",
        "        'Dönmeh': 'Islam',\n",
        "        'feminazism': 'feminism nazi',\n",
        "        'Quroa': 'Quora',\n",
        "        'QUORA': 'Quora',\n",
        "        'langague': 'language',\n",
        "        '(H|h)ongkongese': 'HongKong people',\n",
        "        '(K|k)ashmirians': 'Kashmirian',\n",
        "        '(C|c)hodu': 'fucker',\n",
        "        'penish': 'penis',\n",
        "        'micropenis': 'small penis',\n",
        "        'Madridiots': 'Madrid idiot',\n",
        "        'Ambedkarites': 'Dalit Buddhist movement',\n",
        "        'ReleaseTheMemo': 'cry for the right and Trump supporters',\n",
        "        'harrase': 'harass',\n",
        "        '(B|b)arracoon': 'Black slave',\n",
        "        '(C|c)astrater': 'castration',\n",
        "        '(R|r)apistan': 'rapist Pakistan',\n",
        "        '(T|t)urkified': 'Turkification',\n",
        "        'Dumbassistan': 'dumb ass Pakistan',\n",
        "        'facetards': 'Facebook retards',\n",
        "        'rapefugees': 'rapist refugee',\n",
        "        'superficious': 'superficial',\n",
        "        # extra from kagglers\n",
        "        'colour': 'color',\n",
        "        'centre': 'center',\n",
        "        'favourite': 'favorite',\n",
        "        'travelling': 'traveling',\n",
        "        'counselling': 'counseling',\n",
        "        'theatre': 'theater',\n",
        "        'cancelled': 'canceled',\n",
        "        'labour': 'labor',\n",
        "        'organisation': 'organization',\n",
        "        'wwii': 'world war 2',\n",
        "        'citicise': 'criticize',\n",
        "        'youtu ': 'youtube ',\n",
        "        'Qoura': 'Quora',\n",
        "        'sallary': 'salary',\n",
        "        'Whta': 'What',\n",
        "        'narcisist': 'narcissist',\n",
        "        'narcissit': 'narcissist',\n",
        "        'howdo': 'how do',\n",
        "        'whatare': 'what are',\n",
        "        'howcan': 'how can',\n",
        "        'howmuch': 'how much',\n",
        "        'howmany': 'how many',\n",
        "        'whydo': 'why do',\n",
        "        'doI': 'do I',\n",
        "        'theBest': 'the best',\n",
        "        'howdoes': 'how does',\n",
        "        'mastrubation': 'masturbation',\n",
        "        'mastrubate': 'masturbate',\n",
        "        'mastrubating': 'masturbating',\n",
        "        'pennis': 'penis',\n",
        "        'Etherium': 'Ethereum',\n",
        "        'bigdata': 'big data',\n",
        "        '2k17': '2017',\n",
        "        '2k18': '2018',\n",
        "        'qouta': 'quota',\n",
        "        'exboyfriend': 'ex boyfriend',\n",
        "        'airhostess': 'air hostess',\n",
        "        'whst': 'what',\n",
        "        'watsapp': 'whatsapp',\n",
        "        'demonitisation': 'demonetization',\n",
        "        'demonitization': 'demonetization',\n",
        "        'demonetisation': 'demonetization'\n",
        "    }\n",
        "    misspell_re = re.compile('(%s)' % '|'.join(misspell_to_sub.keys()))\n",
        "\n",
        "    def _replace(match):\n",
        "        \n",
        "        \"\"\"\n",
        "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
        "        \"\"\"\n",
        "        return misspell_to_sub.get(match.group(0), match.group(0))\n",
        "    return misspell_re.sub(_replace, text)\n",
        "\n",
        "def spacing_misspell(text):\n",
        "    \"\"\"\n",
        "    'deadbody' -> 'dead body'\n",
        "    \"\"\"\n",
        "    misspell_list = [\n",
        "        'body',\n",
        "        '(D|d)ead',\n",
        "        '(N|n)orth',\n",
        "        '(K|k)orea',\n",
        "        'matrix',\n",
        "        '(S|s)hit',\n",
        "        '(F|f)uck',\n",
        "        '(F|f)uk',\n",
        "        '(F|f)ck',\n",
        "        '(D|d)ick',\n",
        "        'Trump',\n",
        "        '\\W(A|a)nti',\n",
        "        '(W|w)hy',\n",
        "        # 'Jew',\n",
        "        'bait',\n",
        "        'care',\n",
        "        'troll',\n",
        "        'over',\n",
        "        'gender',\n",
        "        'people',\n",
        "        'kind',\n",
        "        '(S|s)ick',\n",
        "        '(S|s)uck',\n",
        "        '(I|i)diot',\n",
        "        # 'hole(s|)\\W',\n",
        "        '(B|b)ooty',\n",
        "        '(C|c)oin(s|)\\W',\n",
        "        '\\W(N|n)igger'\n",
        "    ]\n",
        "    misspell_re = re.compile('(%s)' % '|'.join(misspell_list))\n",
        "    return misspell_re.sub(r\" \\1 \", text)\n",
        "\n",
        "\n",
        "def clean_latex(text):\n",
        "    \"\"\"\n",
        "    convert r\"[math]\\vec{x} + \\vec{y}\" to English\n",
        "    \"\"\"\n",
        "    # edge case\n",
        "    text = re.sub(r'\\[math\\]', ' LaTex math ', text)\n",
        "    text = re.sub(r'\\[\\/math\\]', ' LaTex math ', text)\n",
        "    text = re.sub(r'\\\\', ' LaTex ', text)\n",
        "\n",
        "    pattern_to_sub = {\n",
        "        r'\\\\mathrm': ' LaTex math mode ',\n",
        "        r'\\\\mathbb': ' LaTex math mode ',\n",
        "        r'\\\\boxed': ' LaTex equation ',\n",
        "        r'\\\\begin': ' LaTex equation ',\n",
        "        r'\\\\end': ' LaTex equation ',\n",
        "        r'\\\\left': ' LaTex equation ',\n",
        "        r'\\\\right': ' LaTex equation ',\n",
        "        r'\\\\(over|under)brace': ' LaTex equation ',\n",
        "        r'\\\\text': ' LaTex equation ',\n",
        "        r'\\\\vec': ' vector ',\n",
        "        r'\\\\var': ' variable ',\n",
        "        r'\\\\theta': ' theta ',\n",
        "        r'\\\\mu': ' average ',\n",
        "        r'\\\\min': ' minimum ',\n",
        "        r'\\\\max': ' maximum ',\n",
        "        r'\\\\sum': ' + ',\n",
        "        r'\\\\times': ' * ',\n",
        "        r'\\\\cdot': ' * ',\n",
        "        r'\\\\hat': ' ^ ',\n",
        "        r'\\\\frac': ' / ',\n",
        "        r'\\\\div': ' / ',\n",
        "        r'\\\\sin': ' Sine ',\n",
        "        r'\\\\cos': ' Cosine ',\n",
        "        r'\\\\tan': ' Tangent ',\n",
        "        r'\\\\infty': ' infinity ',\n",
        "        r'\\\\int': ' integer ',\n",
        "        r'\\\\in': ' in ',\n",
        "    }\n",
        "    # post process for look up\n",
        "    pattern_dict = {k.strip('\\\\'): v for k, v in pattern_to_sub.items()}\n",
        "    # init re\n",
        "    patterns = pattern_to_sub.keys()\n",
        "    pattern_re = re.compile('(%s)' % '|'.join(patterns))\n",
        "\n",
        "    def _replace(match):\n",
        "        \"\"\"\n",
        "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
        "        \"\"\"\n",
        "        return pattern_dict.get(match.group(0).strip('\\\\'), match.group(0))\n",
        "    return pattern_re.sub(_replace, text)\n",
        "\n",
        "\n",
        "def normalize_unicode(text):\n",
        "    \"\"\"\n",
        "    unicode string normalization\n",
        "    \"\"\"\n",
        "    return unicodedata.normalize('NFKD', text)\n",
        "\n",
        "\n",
        "def remove_newline(text):\n",
        "    \"\"\"\n",
        "    remove \\n and  \\t\n",
        "    \"\"\"\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\t', ' ', text)\n",
        "    text = re.sub('\\b', ' ', text)\n",
        "    text = re.sub('\\r', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def decontracted(text):\n",
        "    \"\"\"\n",
        "    de-contract the contraction\n",
        "    \"\"\"\n",
        "    # specific\n",
        "    text = re.sub(r\"(W|w)on(\\'|\\’)t\", \"will not\", text)\n",
        "    text = re.sub(r\"(C|c)an(\\'|\\’)t\", \"can not\", text)\n",
        "    text = re.sub(r\"(Y|y)(\\'|\\’)all\", \"you all\", text)\n",
        "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll\", \"you all\", text)\n",
        "\n",
        "    # general\n",
        "    text = re.sub(r\"(I|i)(\\'|\\’)m\", \"i am\", text)\n",
        "    text = re.sub(r\"(A|a)in(\\'|\\’)t\", \"is not\", text)\n",
        "    text = re.sub(r\"n(\\'|\\’)t\", \" not\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)re\", \" are\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)s\", \" is\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)d\", \" would\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)ll\", \" will\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)t\", \" not\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)ve\", \" have\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def spacing_punctuation(text):\n",
        "    \"\"\"\n",
        "    add space before and after punctuation and symbols\n",
        "    \"\"\"\n",
        "    regular_punct = list(string.punctuation)\n",
        "    extra_punct = [\n",
        "        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
        "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
        "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
        "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
        "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
        "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
        "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
        "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
        "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
        "    all_punct = ''.join(sorted(list(set(regular_punct + extra_punct))))\n",
        "    re_tok = re.compile(f'([{all_punct}])')\n",
        "    return re_tok.sub(r' \\1 ', text)\n",
        "\n",
        "\n",
        "def spacing_digit(text):\n",
        "    \"\"\"\n",
        "    add space before and after digits\n",
        "    \"\"\"\n",
        "    re_tok = re.compile('([0-9])')\n",
        "    return re_tok.sub(r' \\1 ', text)\n",
        "\n",
        "\n",
        "def spacing_number(text):\n",
        "    \"\"\"\n",
        "    add space before and after numbers\n",
        "    \"\"\"\n",
        "    re_tok = re.compile('([0-9]{1,})')\n",
        "    return re_tok.sub(r' \\1 ', text)\n",
        "\n",
        "\n",
        "def remove_number(text):\n",
        "    \"\"\"\n",
        "    numbers are not toxic\n",
        "    \"\"\"\n",
        "    return re.sub('\\d+', ' ', text)\n",
        "\n",
        "\n",
        "def remove_space(text):\n",
        "    \"\"\"\n",
        "    remove extra spaces and ending space if any\n",
        "    \"\"\"\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('\\s+$', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "tokenizer\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def preprocess(text, remove_num=True):\n",
        "    \"\"\"\n",
        "    preprocess text into clean text for tokenization\n",
        "    NOTE:\n",
        "        1. glove supports uppper case words\n",
        "        2. glove supports digit\n",
        "        3. glove supports punctuation\n",
        "        5. glove supports domains e.g. www.apple.com\n",
        "        6. glove supports misspelled words e.g. FUCKKK\n",
        "    \"\"\"\n",
        "    # # 1. normalize\n",
        "    text = normalize_unicode(text)\n",
        "    # # 2. remove new line\n",
        "    text = remove_newline(text)\n",
        "    # 3. de-contract\n",
        "    text = decontracted(text)\n",
        "    # 4. clean misspell\n",
        "    text = clean_misspell(text)\n",
        "    # 5. space misspell\n",
        "    #text = spacing_misspell(text)\n",
        "    # 6. clean_latex\n",
        "    text = clean_latex(text)\n",
        "    # 7. space\n",
        "    text = spacing_punctuation(text)\n",
        "    # 8. handle number\n",
        "    if remove_num:\n",
        "        text = remove_number(text)\n",
        "    else:\n",
        "        text = spacing_digit(text)\n",
        "    # 9. remove space\n",
        "    text = remove_space(text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnnRRyGVflEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9037b137-3319-48a3-f9ef-01c0479da08f"
      },
      "source": [
        "df[\"question_text\"] = df[\"question_text\"].progress_apply(preprocess)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [04:44<00:00, 4590.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybQE7uEtft0_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c121f482-84d6-48b2-f028-605d6dc5ce2e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W6fTSsZljJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def lemmatize_text(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9RlMjrVmKgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['question_text'] = df.question_text.apply(lemmatize_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dPTKNjNmPKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZNHX3venD41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "bad28118-b280-46e1-e961-4f923b249537"
      },
      "source": [
        "sentences = df[\"question_text\"]\n",
        "vocab = build_vocab(sentences)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1306122 [00:00<?, ?it/s]\u001b[A\n",
            "  2%|▏         | 25227/1306122 [00:00<00:05, 252265.43it/s]\u001b[A\n",
            "  4%|▍         | 51267/1306122 [00:00<00:04, 254646.30it/s]\u001b[A\n",
            "  6%|▌         | 76927/1306122 [00:00<00:04, 255221.73it/s]\u001b[A\n",
            "  8%|▊         | 102951/1306122 [00:00<00:04, 256706.30it/s]\u001b[A\n",
            " 10%|▉         | 129143/1306122 [00:00<00:04, 258246.19it/s]\u001b[A\n",
            " 12%|█▏        | 155785/1306122 [00:00<00:04, 260644.89it/s]\u001b[A\n",
            " 14%|█▍        | 180144/1306122 [00:00<00:04, 255280.22it/s]\u001b[A\n",
            " 16%|█▌        | 205940/1306122 [00:00<00:04, 256078.18it/s]\u001b[A\n",
            " 18%|█▊        | 231784/1306122 [00:00<00:04, 256780.06it/s]\u001b[A\n",
            " 20%|█▉        | 257038/1306122 [00:01<00:04, 255491.58it/s]\u001b[A\n",
            " 22%|██▏       | 283562/1306122 [00:01<00:03, 258338.48it/s]\u001b[A\n",
            " 24%|██▎       | 309153/1306122 [00:01<00:03, 257598.32it/s]\u001b[A\n",
            " 26%|██▌       | 335287/1306122 [00:01<00:03, 258708.50it/s]\u001b[A\n",
            " 28%|██▊       | 361398/1306122 [00:01<00:03, 259423.45it/s]\u001b[A\n",
            " 30%|██▉       | 387707/1306122 [00:01<00:03, 260506.99it/s]\u001b[A\n",
            " 32%|███▏      | 413645/1306122 [00:01<00:03, 257303.92it/s]\u001b[A\n",
            " 34%|███▎      | 439305/1306122 [00:01<00:03, 250916.17it/s]\u001b[A\n",
            " 36%|███▌      | 465354/1306122 [00:01<00:03, 253712.79it/s]\u001b[A\n",
            " 38%|███▊      | 491097/1306122 [00:01<00:03, 254814.90it/s]\u001b[A\n",
            " 40%|███▉      | 516578/1306122 [00:02<00:03, 250030.30it/s]\u001b[A\n",
            " 41%|████▏     | 541601/1306122 [00:02<00:03, 241125.12it/s]\u001b[A\n",
            " 43%|████▎     | 566610/1306122 [00:02<00:03, 243745.25it/s]\u001b[A\n",
            " 45%|████▌     | 591049/1306122 [00:02<00:02, 243900.42it/s]\u001b[A\n",
            " 47%|████▋     | 616812/1306122 [00:02<00:02, 247859.29it/s]\u001b[A\n",
            " 49%|████▉     | 642004/1306122 [00:02<00:02, 249062.00it/s]\u001b[A\n",
            " 51%|█████     | 668763/1306122 [00:02<00:02, 254343.97it/s]\u001b[A\n",
            " 53%|█████▎    | 694352/1306122 [00:02<00:02, 254803.89it/s]\u001b[A\n",
            " 55%|█████▌    | 722732/1306122 [00:02<00:02, 262859.41it/s]\u001b[A\n",
            " 57%|█████▋    | 750912/1306122 [00:02<00:02, 268267.36it/s]\u001b[A\n",
            " 60%|█████▉    | 779468/1306122 [00:03<00:01, 273230.87it/s]\u001b[A\n",
            " 62%|██████▏   | 806877/1306122 [00:03<00:01, 273360.53it/s]\u001b[A\n",
            " 64%|██████▍   | 834353/1306122 [00:03<00:01, 273774.07it/s]\u001b[A\n",
            " 66%|██████▌   | 862888/1306122 [00:03<00:01, 277146.33it/s]\u001b[A\n",
            " 68%|██████▊   | 890642/1306122 [00:03<00:01, 276647.64it/s]\u001b[A\n",
            " 70%|███████   | 918335/1306122 [00:03<00:01, 271011.69it/s]\u001b[A\n",
            " 72%|███████▏  | 946657/1306122 [00:03<00:01, 274560.78it/s]\u001b[A\n",
            " 75%|███████▍  | 974156/1306122 [00:03<00:01, 272495.32it/s]\u001b[A\n",
            " 77%|███████▋  | 1001769/1306122 [00:03<00:01, 273573.97it/s]\u001b[A\n",
            " 79%|███████▉  | 1029908/1306122 [00:03<00:01, 275870.95it/s]\u001b[A\n",
            " 81%|████████  | 1058369/1306122 [00:04<00:00, 278432.36it/s]\u001b[A\n",
            " 83%|████████▎ | 1086829/1306122 [00:04<00:00, 280253.69it/s]\u001b[A\n",
            " 85%|████████▌ | 1114927/1306122 [00:04<00:00, 280469.67it/s]\u001b[A\n",
            " 88%|████████▊ | 1142987/1306122 [00:04<00:00, 278181.83it/s]\u001b[A\n",
            " 90%|████████▉ | 1170827/1306122 [00:04<00:00, 278245.53it/s]\u001b[A\n",
            " 92%|█████████▏| 1198841/1306122 [00:04<00:00, 278810.46it/s]\u001b[A\n",
            " 94%|█████████▍| 1226729/1306122 [00:04<00:00, 277622.12it/s]\u001b[A\n",
            " 96%|█████████▌| 1254497/1306122 [00:04<00:00, 274594.93it/s]\u001b[A\n",
            " 98%|█████████▊| 1281975/1306122 [00:04<00:00, 274648.74it/s]\u001b[A\n",
            "100%|██████████| 1306122/1306122 [00:04<00:00, 264523.09it/s]\u001b[A"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy6S6xQgnV9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c69c77b9-b996-47eb-cded-d1eb945d00fa"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "213649"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoRcrT_Fnvvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator \n",
        "\n",
        "def check_coverage(vocab,embeddings_index):\n",
        "    a = {}\n",
        "    oov = {}\n",
        "    k = 0\n",
        "    i = 0\n",
        "    for word in tqdm(vocab):\n",
        "        try:\n",
        "            a[word] = embeddings_index[word]\n",
        "            k += vocab[word]\n",
        "        except:\n",
        "\n",
        "            oov[word] = vocab[word]\n",
        "            i += vocab[word]\n",
        "            pass\n",
        "\n",
        "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
        "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
        "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
        "\n",
        "    return sorted_x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz-PbOXdn3vZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "eedfae1c-1fbe-485d-82d2-7a7ca0e63a1e"
      },
      "source": [
        "oov = check_coverage(vocab,glove_dic)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/213649 [00:00<?, ?it/s]\u001b[A\n",
            " 22%|██▏       | 48028/213649 [00:00<00:00, 479555.57it/s]\u001b[A\n",
            " 47%|████▋     | 100039/213649 [00:00<00:00, 491040.75it/s]\u001b[A\n",
            " 72%|███████▏  | 152828/213649 [00:00<00:00, 501542.91it/s]\u001b[A\n",
            " 96%|█████████▋| 205903/213649 [00:00<00:00, 509958.48it/s]\u001b[A\n",
            "100%|██████████| 213649/213649 [00:00<00:00, 509928.95it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found embeddings for 74.13% of vocab\n",
            "Found embeddings for  99.61% of all text\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF8pJrm-n7fd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0a918745-7690-4b44-8de3-07d362e76259"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(df, test_size=0.1, random_state=42)\n",
        "n_words = 50000\n",
        "tokenizer = Tokenizer(num_words=n_words)\n",
        "tokenizer.fit_on_texts(list(train.question_text))\n",
        "\n",
        "q_train = tokenizer.texts_to_sequences(train.question_text)\n",
        "q_val = tokenizer.texts_to_sequences(val.question_text)\n",
        "#q_test = tokenizer.texts_to_sequences(df_test.question_text)\n",
        "\n",
        "max_len = 65\n",
        "q_train = pad_sequences(q_train,maxlen=max_len)\n",
        "q_val = pad_sequences(q_val,maxlen=max_len)\n",
        "#q_test = pad_sequences(q_test,maxlen=max_len)\n",
        "\n",
        "y_train = train.target\n",
        "y_val = val.target\n",
        "\n",
        "del train,val\n",
        "word_index = tokenizer.word_index\n",
        "emb_size = glove_dic['.'].shape[0]\n",
        "emb_matrix = np.zeros((n_words,emb_size))\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        continue\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        emb_matrix[index,:] = vec\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kWjTh27oBhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "#find the best threshold\n",
        "def optim_thres(y_val,y_pred):\n",
        "    score = 0\n",
        "    thresholds = np.arange(0.1,0.501,0.01)\n",
        "    for thres in thresholds:\n",
        "        thres = np.round(thres,2)\n",
        "        temp_pred = (y_pred > thres).astype(int)\n",
        "        temp_score = f1_score(y_val,temp_pred)\n",
        "        print(\"Thres: {} --------- F1: {}\".format(thres,temp_score))\n",
        "        if temp_score > score:\n",
        "            score = temp_score\n",
        "            final_thres = thres\n",
        "    return final_thres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSAg9QP3oIE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import gensim as gn\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from keras.layers import LSTM,Bidirectional,TimeDistributed, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout\n",
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential,Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "        \n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        \n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1UJxao9pnLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import LSTM,Bidirectional,TimeDistributed, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout,Conv1D,SpatialDropout1D,GlobalAveragePooling1D\n",
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding,Flatten,Dense\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers.normalization import BatchNormalization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlMCbAagpre3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "464edaea-a614-4d05-f478-762eb9c1e7b1"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "#x = Embedding(input_dim=n_words,output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
        "#x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x =  Bidirectional(CuDNNGRU(100,return_sequences=True))(x)\n",
        "x = Attention(step_dim=max_len)(x)\n",
        "x = Dense(36,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 65)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 65, 300)           15000000  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 65, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 65, 200)           321600    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 65, 200)           181200    \n",
            "_________________________________________________________________\n",
            "attention_1 (Attention)      (None, 200)               265       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 36)                7236      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 37        \n",
            "=================================================================\n",
            "Total params: 15,510,338\n",
            "Trainable params: 15,510,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFBlKEzmp8no",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "43ff3be0-491d-41d4-8fc6-fef573bffd4c"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n",
        "                     validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 163s 139us/step - loss: 0.1276 - acc: 0.9511 - f1: 0.5214 - val_loss: 0.1112 - val_acc: 0.9569 - val_f1: 0.5559\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.55586, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 166s 141us/step - loss: 0.1088 - acc: 0.9568 - f1: 0.6078 - val_loss: 0.1013 - val_acc: 0.9598 - val_f1: 0.6364\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.55586 to 0.63642, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 167s 142us/step - loss: 0.1032 - acc: 0.9590 - f1: 0.6357 - val_loss: 0.0976 - val_acc: 0.9606 - val_f1: 0.6564\n",
            "\n",
            "Epoch 00003: val_f1 improved from 0.63642 to 0.65639, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 168s 143us/step - loss: 0.0990 - acc: 0.9604 - f1: 0.6526 - val_loss: 0.0967 - val_acc: 0.9606 - val_f1: 0.6691\n",
            "\n",
            "Epoch 00004: val_f1 improved from 0.65639 to 0.66913, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 168s 143us/step - loss: 0.0956 - acc: 0.9617 - f1: 0.6678 - val_loss: 0.0946 - val_acc: 0.9617 - val_f1: 0.6651\n",
            "\n",
            "Epoch 00005: val_f1 did not improve from 0.66913\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 168s 143us/step - loss: 0.0925 - acc: 0.9626 - f1: 0.6784 - val_loss: 0.0939 - val_acc: 0.9621 - val_f1: 0.6680\n",
            "\n",
            "Epoch 00006: val_f1 did not improve from 0.66913\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 169s 143us/step - loss: 0.0900 - acc: 0.9639 - f1: 0.6905 - val_loss: 0.0943 - val_acc: 0.9625 - val_f1: 0.6602\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.66913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhaVBaMeqK5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "75883fef-515b-4931-c5a6-0b6f504e4dbe"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "#x = Embedding(input_dim=n_words,output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
        "#x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "#x =  Bidirectional(CuDNNGRU(100,return_sequences=True))(x)\n",
        "x = Attention(step_dim=max_len)(x)\n",
        "x = Dense(36,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 65)                0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 65, 300)           15000000  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 65, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_5 (Bidirection (None, 65, 200)           321600    \n",
            "_________________________________________________________________\n",
            "attention_3 (Attention)      (None, 200)               265       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 36)                7236      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 37        \n",
            "=================================================================\n",
            "Total params: 15,329,138\n",
            "Trainable params: 15,329,138\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWZBZSKpvCcI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "3d04a59d-e282-417d-a505-d8d870833dd2"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n",
        "                     validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 102s 87us/step - loss: 0.1266 - acc: 0.9518 - f1: 0.5324 - val_loss: 0.1036 - val_acc: 0.9589 - val_f1: 0.6472\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.64718, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 104s 89us/step - loss: 0.1014 - acc: 0.9594 - f1: 0.6408 - val_loss: 0.0977 - val_acc: 0.9604 - val_f1: 0.6427\n",
            "\n",
            "Epoch 00002: val_f1 did not improve from 0.64718\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 106s 90us/step - loss: 0.0935 - acc: 0.9625 - f1: 0.6764 - val_loss: 0.0967 - val_acc: 0.9612 - val_f1: 0.6538\n",
            "\n",
            "Epoch 00003: val_f1 improved from 0.64718 to 0.65384, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 107s 91us/step - loss: 0.0869 - acc: 0.9652 - f1: 0.7048 - val_loss: 0.0972 - val_acc: 0.9610 - val_f1: 0.6548\n",
            "\n",
            "Epoch 00004: val_f1 improved from 0.65384 to 0.65481, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 107s 91us/step - loss: 0.0808 - acc: 0.9675 - f1: 0.7282 - val_loss: 0.0996 - val_acc: 0.9612 - val_f1: 0.6449\n",
            "\n",
            "Epoch 00005: val_f1 did not improve from 0.65481\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 107s 91us/step - loss: 0.0749 - acc: 0.9700 - f1: 0.7499 - val_loss: 0.1069 - val_acc: 0.9593 - val_f1: 0.6696\n",
            "\n",
            "Epoch 00006: val_f1 improved from 0.65481 to 0.66963, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 107s 91us/step - loss: 0.0690 - acc: 0.9722 - f1: 0.7700 - val_loss: 0.1100 - val_acc: 0.9601 - val_f1: 0.6592\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.66963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuF-L-pxvLc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "4b08b78e-2199-4cd9-e075-297db1183405"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "#x = Embedding(input_dim=n_words,output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
        "#x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "#x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x =  Bidirectional(CuDNNGRU(100,return_sequences=True))(x)\n",
        "x = Attention(step_dim=max_len)(x)\n",
        "x = Dense(36,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 65)                0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 65, 300)           15000000  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_4 (Spatial (None, 65, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 65, 200)           241200    \n",
            "_________________________________________________________________\n",
            "attention_4 (Attention)      (None, 200)               265       \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 36)                7236      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 37        \n",
            "=================================================================\n",
            "Total params: 15,248,738\n",
            "Trainable params: 15,248,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmKX1uWryNud",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "63e3516f-cc48-4fdb-ae8f-bd22d8a2180b"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n",
        "                     validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 92s 79us/step - loss: 0.1254 - acc: 0.9523 - f1: 0.5403 - val_loss: 0.1015 - val_acc: 0.9592 - val_f1: 0.6389\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.63886, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 93s 79us/step - loss: 0.1015 - acc: 0.9594 - f1: 0.6385 - val_loss: 0.0975 - val_acc: 0.9609 - val_f1: 0.6569\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.63886 to 0.65692, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 94s 80us/step - loss: 0.0936 - acc: 0.9626 - f1: 0.6764 - val_loss: 0.0968 - val_acc: 0.9615 - val_f1: 0.6633\n",
            "\n",
            "Epoch 00003: val_f1 improved from 0.65692 to 0.66328, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 94s 80us/step - loss: 0.0870 - acc: 0.9650 - f1: 0.7029 - val_loss: 0.0993 - val_acc: 0.9609 - val_f1: 0.6550\n",
            "\n",
            "Epoch 00004: val_f1 did not improve from 0.66328\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 94s 80us/step - loss: 0.0806 - acc: 0.9677 - f1: 0.7292 - val_loss: 0.1006 - val_acc: 0.9603 - val_f1: 0.6662\n",
            "\n",
            "Epoch 00005: val_f1 improved from 0.66328 to 0.66618, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 95s 80us/step - loss: 0.0741 - acc: 0.9704 - f1: 0.7529 - val_loss: 0.1081 - val_acc: 0.9605 - val_f1: 0.6384\n",
            "\n",
            "Epoch 00006: val_f1 did not improve from 0.66618\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 95s 81us/step - loss: 0.0680 - acc: 0.9727 - f1: 0.7738 - val_loss: 0.1123 - val_acc: 0.9597 - val_f1: 0.6463\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.66618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkkljbiCyTNC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "4c199d5e-82e2-4ea3-a293-0a038e809976"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "#x = Embedding(input_dim=n_words,output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
        "#x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "#x = Attention(step_dim=max_len)(x)\n",
        "x=  Conv1D(128,30,activation='relu')(x)\n",
        "x = GlobalMaxPool1D()(x)\n",
        "x = Dense(60,activation='relu')(x)\n",
        "x = Dense(38,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        (None, 65)                0         \n",
            "_________________________________________________________________\n",
            "embedding_16 (Embedding)     (None, 65, 300)           15000000  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_15 (Spatia (None, 65, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_17 (Bidirectio (None, 65, 200)           321600    \n",
            "_________________________________________________________________\n",
            "conv1d_15 (Conv1D)           (None, 36, 128)           768128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 60)                7740      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 38)                2318      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 38)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 1)                 39        \n",
            "=================================================================\n",
            "Total params: 16,099,825\n",
            "Trainable params: 16,099,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls5BeFjO4OIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "96eac0cc-37af-47d0-f65f-0cef11b253d5"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n",
        "                     validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 144s 122us/step - loss: 0.1227 - acc: 0.9519 - f1: 0.5461 - val_loss: 0.1012 - val_acc: 0.9591 - val_f1: 0.6325\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.63253, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 148s 126us/step - loss: 0.1015 - acc: 0.9593 - f1: 0.6400 - val_loss: 0.0969 - val_acc: 0.9603 - val_f1: 0.6635\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.63253 to 0.66353, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0931 - acc: 0.9625 - f1: 0.6769 - val_loss: 0.0972 - val_acc: 0.9614 - val_f1: 0.6619\n",
            "\n",
            "Epoch 00003: val_f1 did not improve from 0.66353\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0857 - acc: 0.9653 - f1: 0.7061 - val_loss: 0.0975 - val_acc: 0.9610 - val_f1: 0.6442\n",
            "\n",
            "Epoch 00004: val_f1 did not improve from 0.66353\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0784 - acc: 0.9682 - f1: 0.7343 - val_loss: 0.1017 - val_acc: 0.9600 - val_f1: 0.6752\n",
            "\n",
            "Epoch 00005: val_f1 improved from 0.66353 to 0.67522, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0708 - acc: 0.9713 - f1: 0.7624 - val_loss: 0.1060 - val_acc: 0.9601 - val_f1: 0.6625\n",
            "\n",
            "Epoch 00006: val_f1 did not improve from 0.67522\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0631 - acc: 0.9746 - f1: 0.7908 - val_loss: 0.1192 - val_acc: 0.9592 - val_f1: 0.6664\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.67522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7H9BmMS5PPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "c7608ca2-cc86-4ac9-f142-bf1c9f70a65d"
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "x = SpatialDropout1D(0.3)(x)\n",
        "#x = Embedding(input_dim=n_words,output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
        "#x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "#x = Attention(step_dim=max_len)(x)\n",
        "x=  Conv1D(128,30,activation='relu')(x)\n",
        "#x = GlobalMaxPool1D()(x)\n",
        "x= GlobalAveragePooling1D()(x)\n",
        "x = Dense(60,activation='relu')(x)\n",
        "x = Dense(38,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_19 (InputLayer)        (None, 65)                0         \n",
            "_________________________________________________________________\n",
            "embedding_19 (Embedding)     (None, 65, 300)           15000000  \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_18 (Spatia (None, 65, 300)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_20 (Bidirectio (None, 65, 200)           321600    \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 36, 128)           768128    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 60)                7740      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 38)                2318      \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 38)                0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 39        \n",
            "=================================================================\n",
            "Total params: 16,099,825\n",
            "Trainable params: 16,099,825\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mrvy7DQ9FcfP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "8702b9e7-2ed3-4cd8-cb3a-d63be248852b"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,\n",
        "                     validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 143s 122us/step - loss: 0.1226 - acc: 0.9526 - f1: 0.5445 - val_loss: 0.1021 - val_acc: 0.9594 - val_f1: 0.6231\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.62315, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.1025 - acc: 0.9590 - f1: 0.6375 - val_loss: 0.0980 - val_acc: 0.9610 - val_f1: 0.6490\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.62315 to 0.64897, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0940 - acc: 0.9622 - f1: 0.6742 - val_loss: 0.1002 - val_acc: 0.9616 - val_f1: 0.6492\n",
            "\n",
            "Epoch 00003: val_f1 improved from 0.64897 to 0.64918, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0875 - acc: 0.9646 - f1: 0.6992 - val_loss: 0.0969 - val_acc: 0.9616 - val_f1: 0.6563\n",
            "\n",
            "Epoch 00004: val_f1 improved from 0.64918 to 0.65631, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0812 - acc: 0.9671 - f1: 0.7231 - val_loss: 0.1008 - val_acc: 0.9611 - val_f1: 0.6633\n",
            "\n",
            "Epoch 00005: val_f1 improved from 0.65631 to 0.66334, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0750 - acc: 0.9696 - f1: 0.7467 - val_loss: 0.1067 - val_acc: 0.9605 - val_f1: 0.6446\n",
            "\n",
            "Epoch 00006: val_f1 did not improve from 0.66334\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 149s 127us/step - loss: 0.0688 - acc: 0.9721 - f1: 0.7681 - val_loss: 0.1117 - val_acc: 0.9597 - val_f1: 0.6640\n",
            "\n",
            "Epoch 00007: val_f1 improved from 0.66334 to 0.66404, saving model to ./lstm_glove_emb.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDf2eNs0GDgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}