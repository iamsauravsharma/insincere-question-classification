{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm+gru in parallel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamsauravsharma/insincere-question-classification/blob/bishal/lstm%2Bgru_in_parallel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "q8lfisK1fLoi",
        "colab_type": "code",
        "colab": {},
        "outputId": "81b70e62-69ae-41ef-b1de-093edd7ebb9b"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['train.csv', 'sample_submission.csv', 'embeddings', 'test.csv']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "oEBGU0OkfLot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"../input/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J57wm9KIfLox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_file = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
        "#emb_file_par =  '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gjB475EUfLo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aB_dnNLcfLo6",
        "colab_type": "code",
        "colab": {},
        "outputId": "57aea133-1d69-45ed-c242-d4c2eeba56e5"
      },
      "source": [
        "\n",
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab\n",
        "sentences = df[\"question_text\"].apply(lambda x: x.split()).values\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:05<00:00, 230639.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iQxJPetnfLpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embed(file):\n",
        "    embeddings_index = {}\n",
        "    f = open(file)\n",
        "    #f = open('../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt',encoding=\"utf8\", errors='ignore')\n",
        "    for line in tqdm(f):\n",
        "        values = line.split(\" \")\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()        \n",
        "    return embeddings_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RZJO3f5lfLpG",
        "colab_type": "code",
        "colab": {},
        "outputId": "10b3c034-86bc-4e8c-e084-0996aa46a9da"
      },
      "source": [
        "glove_dic = load_embed(emb_file)\n",
        "#glove_dic1=  load_embed(emb_file_par)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2196017it [03:21, 10882.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "m5s_kKyUfLpM",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d0d0c99-017c-4daa-9859-e648630a8572"
      },
      "source": [
        "n_words = len(vocab)+1\n",
        "del vocab\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val = train_test_split(df, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=n_words)\n",
        "tokenizer.fit_on_texts(list(train.question_text))\n",
        "\n",
        "q_train = tokenizer.texts_to_sequences(train.question_text)\n",
        "q_val = tokenizer.texts_to_sequences(val.question_text)\n",
        "#q_test = tokenizer.texts_to_sequences(df_test.question_text)\n",
        "\n",
        "max_len = 65\n",
        "q_train = pad_sequences(q_train,maxlen=max_len)\n",
        "q_val = pad_sequences(q_val,maxlen=max_len)\n",
        "#q_test = pad_sequences(q_test,maxlen=max_len)\n",
        "\n",
        "y_train = train.target\n",
        "y_val = val.target\n",
        "\n",
        "del train,val\n",
        "word_index = tokenizer.word_index\n",
        "emb_size = glove_dic['.'].shape[0]\n",
        "emb_matrix = np.zeros((n_words,emb_size))\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        \n",
        "        continue\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "    w = w.lower()\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "    w = w.upper()\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "\n",
        "    w = w.capitalize()\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XxGr34ObfLpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del glove_dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vFpR8FvIfLpY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "emb_matrix_par = np.zeros((n_words,emb_size))\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        \n",
        "        continue\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "    w = w.lower()\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "    w = w.upper()\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "\n",
        "    w = w.capitalize()\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "del glove_dic1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "M67L7uKhfLpg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix_com = np.concatenate((emb_matrix, emb_matrix_par), axis=1)\n",
        "del emb_matrix\n",
        "del emb_matrix_par"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KsIp5JEjfLpl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "#find the best threshold\n",
        "def optim_thres(y_val,y_pred):\n",
        "    score = 0\n",
        "    thresholds = np.arange(0.1,0.501,0.01)\n",
        "    for thres in thresholds:\n",
        "        thres = np.round(thres,2)\n",
        "        temp_pred = (y_pred > thres).astype(int)\n",
        "        temp_score = f1_score(y_val,temp_pred)\n",
        "        print(\"Thres: {} --------- F1: {}\".format(thres,temp_score))\n",
        "        if temp_score > score:\n",
        "            score = temp_score\n",
        "            final_thres = thres\n",
        "    return final_thres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uqEekMQyfLpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import gensim as gn\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from keras.layers import LSTM,Bidirectional,TimeDistributed, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout\n",
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential,Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "        \n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        \n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ko6SQWoSfLpt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import gensim as gn\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from keras.layers import LSTM,Bidirectional,TimeDistributed, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout\n",
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential,Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import LSTM,GRU,Bidirectional,TimeDistributed,Concatenate, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout,Conv1D,SpatialDropout1D,GlobalAveragePooling1D\n",
        "from keras.layers import CuDNNLSTM,CuDNNGRU\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Embedding,Flatten,Dense\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers.normalization import BatchNormalization\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wgk8msCDfLpx",
        "colab_type": "code",
        "colab": {},
        "outputId": "a3ba6f8b-cf15-43bc-9cd9-719e62877f18"
      },
      "source": [
        "emb_size=300\n",
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[emb_matrix])(inp)\n",
        "#x = Embedding(input_dim=n_words,output_dim=embed_size, weights=[embedding_matrix])(inp)\n",
        "x1 = Bidirectional(CuDNNLSTM(100, return_sequences=True))(x)\n",
        "x2 = Bidirectional(CuDNNGRU(100, return_sequences=True))(x)\n",
        "x1 = Conv1D(50,10,activation='relu')(x1)\n",
        "x1 = GlobalMaxPool1D()(x)\n",
        "x2 = Attention(step_dim=max_len)(x2)\n",
        "conc = Concatenate()([x1, x2])\n",
        "x = Dense(128,activation='relu')(conc)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 65)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 65, 300)      152647200   input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) (None, 65, 200)      241200      embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling1d_1 (GlobalM (None, 300)          0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         (None, 200)          265         bidirectional_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 500)          0           global_max_pooling1d_1[0][0]     \n",
            "                                                                 attention_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          64128       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            129         dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 152,952,922\n",
            "Trainable params: 152,952,922\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SealxNAjfLp2",
        "colab_type": "code",
        "colab": {},
        "outputId": "476237b9-8d9c-45a6-ed41-57685400a56d"
      },
      "source": [
        "model_name = 'lstm_glove_emb'\n",
        "checkpoint = ModelCheckpoint(filepath='./{}.hdf5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['acc',f1])\n",
        "history  = model.fit(q_train,y_train,batch_size=1500,epochs=7,validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:107: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 152647200 elements. This may consume a large amount of memory.\n",
            "  num_elements)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 99s 84us/step - loss: 0.1264 - acc: 0.9515 - f1: 0.5205 - val_loss: 0.1040 - val_acc: 0.9584 - val_f1: 0.5949\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.59491, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 89s 75us/step - loss: 0.1026 - acc: 0.9588 - f1: 0.6350 - val_loss: 0.0989 - val_acc: 0.9602 - val_f1: 0.6534\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.59491 to 0.65335, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 89s 76us/step - loss: 0.0957 - acc: 0.9614 - f1: 0.6638 - val_loss: 0.0977 - val_acc: 0.9609 - val_f1: 0.6571\n",
            "\n",
            "Epoch 00003: val_f1 improved from 0.65335 to 0.65706, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 89s 76us/step - loss: 0.0899 - acc: 0.9635 - f1: 0.6873 - val_loss: 0.0972 - val_acc: 0.9609 - val_f1: 0.6529\n",
            "\n",
            "Epoch 00004: val_f1 did not improve from 0.65706\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 89s 75us/step - loss: 0.0846 - acc: 0.9655 - f1: 0.7082 - val_loss: 0.0983 - val_acc: 0.9604 - val_f1: 0.6687\n",
            "\n",
            "Epoch 00005: val_f1 improved from 0.65706 to 0.66866, saving model to ./lstm_glove_emb.hdf5\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 89s 76us/step - loss: 0.0792 - acc: 0.9677 - f1: 0.7301 - val_loss: 0.1022 - val_acc: 0.9609 - val_f1: 0.6637\n",
            "\n",
            "Epoch 00006: val_f1 did not improve from 0.66866\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 89s 75us/step - loss: 0.0733 - acc: 0.9702 - f1: 0.7542 - val_loss: 0.1042 - val_acc: 0.9603 - val_f1: 0.6583\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.66866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L9D0LbntfLp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}