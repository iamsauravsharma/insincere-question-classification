{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lastmodel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLMooA-E-OS9",
        "colab_type": "code",
        "outputId": "53f50bdb-a42f-4449-c74d-a6fc4ae856cc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-82dc4d97-eca9-402e-8cc0-8d48c9db4dfb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-82dc4d97-eca9-402e-8cc0-8d48c9db4dfb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"bishalgaire360\",\"key\":\"69b39489849cd899eaa93339bad30cdb\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CY2ceNBmyVwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0d67efe-f016-4cbf-c52d-7401084ae687"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.engine.topology import Layer\n",
        "from keras.layers import LSTM,Bidirectional,TimeDistributed, Embedding,Dense,Input,GlobalMaxPool1D,Flatten,Dropout,Conv1D,SpatialDropout1D,GlobalAveragePooling1D,CuDNNLSTM,CuDNNGRU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Sequential,Model\n",
        "from keras.optimizers import Adam,Adamax\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from zipfile import ZipFile\n",
        "import gensim as gn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "import string\n",
        "import unicodedata"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMX4BYXV-Tll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O54SiqJr04Cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "03fbeb01-7919-4e79-c9ba-c26d2b74506c"
      },
      "source": [
        "!kaggle competitions download -c quora-insincere-questions-classification"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.csv.zip to /content\n",
            " 88% 48.0M/54.4M [00:00<00:00, 70.0MB/s]\n",
            "100% 54.4M/54.4M [00:00<00:00, 137MB/s] \n",
            "Downloading embeddings.zip to /content\n",
            "100% 5.95G/5.96G [01:24<00:00, 113MB/s]\n",
            "100% 5.96G/5.96G [01:24<00:00, 75.7MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "  0% 0.00/4.08M [00:00<?, ?B/s]\n",
            "100% 4.08M/4.08M [00:00<00:00, 67.1MB/s]\n",
            "Downloading test.csv.zip to /content\n",
            " 32% 5.00M/15.7M [00:00<00:00, 24.3MB/s]\n",
            "100% 15.7M/15.7M [00:00<00:00, 51.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvCKz1ee07wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "075bbf16-b2cc-4858-b7de-6d380bf08939"
      },
      "source": [
        "file_name=\"train.csv.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')\n",
        "file_name=\"embeddings.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "    zip.extractall()\n",
        "    print('Done')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "117d951a-8dbe-4e4b-834a-f9aa1c7a0655",
        "id": "5ZPZ4g7pcPPW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "tqdm.pandas()\n",
        "df=pd.read_csv('train.csv')\n",
        "del df['qid']\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       question_text  target\n",
              "0  How did Quebec nationalists see their province...       0\n",
              "1  Do you have an adopted dog, how would you enco...       0\n",
              "2  Why does velocity affect time? Does velocity a...       0\n",
              "3  How did Otto von Guericke used the Magdeburg h...       0\n",
              "4  Can I convert montra helicon D to a mountain b...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMTqVUYuf1je",
        "colab_type": "code",
        "outputId": "008cb73b-4f4c-4d59-c62d-4e13d645e676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "def build_vocab(sentences, verbose =  True):\n",
        "    \"\"\"\n",
        "    :param sentences: list of list of words\n",
        "    :return: dictionary of words and their count\n",
        "    \"\"\"\n",
        "    vocab = {}\n",
        "    for sentence in tqdm(sentences, disable = (not verbose)):\n",
        "        for word in sentence:\n",
        "            try:\n",
        "                vocab[word] += 1\n",
        "            except KeyError:\n",
        "                vocab[word] = 1\n",
        "    return vocab\n",
        "sentences = df[\"question_text\"].progress_apply(lambda x: x.split()).values\n",
        "vocab = build_vocab(sentences)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [00:05<00:00, 232372.38it/s]\n",
            "100%|██████████| 1306122/1306122 [00:04<00:00, 291392.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yDtQngkDB7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_misspell(text):\n",
        "    \"\"\"\n",
        "    misspell list (quora vs. glove)\n",
        "    \"\"\"\n",
        "    misspell_to_sub = {\n",
        "        '(T|t)erroristan': 'terrorist Pakistan',\n",
        "        'BIMARU': 'Bihar, Madhya Pradesh, Rajasthan, Uttar Pradesh',\n",
        "        '(H|h)induphobic': 'Hindu phobic',\n",
        "        '(H|h)induphobia': 'Hindu phobic',\n",
        "        'Babchenko': 'Arkady Arkadyevich Babchenko faked death',\n",
        "        'Boshniaks': 'Bosniaks',\n",
        "        'Dravidanadu': 'Dravida Nadu',\n",
        "        'mysoginists': 'misogynists',\n",
        "        'MGTOWS': 'Men Going Their Own Way',\n",
        "        'mongloid': 'Mongoloid',\n",
        "        'unsincere': 'insincere',\n",
        "        'meninism': 'male feminism',\n",
        "        'jewplicate': 'jewish replicate',\n",
        "        'unoin': 'Union',\n",
        "        'daesh': 'Islamic State of Iraq and the Levant',\n",
        "        'Kalergi': 'Coudenhove-Kalergi',\n",
        "        ' apist': ' Ape',\n",
        "        '(B|b)hakts': 'Bhakt',\n",
        "        'Tambrahms': 'Tamil Brahmin',\n",
        "        'Pahul': 'Amrit Sanskar',\n",
        "        'SJW(s|)': 'social justice warrior',\n",
        "        'incel(s|)': 'involuntary celibates',\n",
        "        'emiratis': 'Emiratis',\n",
        "        'weatern': 'western',\n",
        "        'Pizzagate': 'Pizzagate conspiracy theory',\n",
        "        'naïve': 'naive',\n",
        "        'Skripal': 'Sergei Skripal',\n",
        "        '(R|r)emainers': 'remainer',\n",
        "        'antibrahmin': 'anti Brahminism',\n",
        "        'HYPSM': ' Harvard, Yale, Princeton, Stanford, MIT',\n",
        "        'HYPS': ' Harvard, Yale, Princeton, Stanford',\n",
        "        'kompromat': 'compromising material',\n",
        "        '(T|t)harki': 'pervert',\n",
        "        'mastuburate': 'masturbate',\n",
        "        'Zoë': 'Zoe',\n",
        "        'indans': 'Indian',\n",
        "        'xender': 'gender',\n",
        "        'Naxali': 'Naxalite',\n",
        "        'Bathla': 'Namit Bathla',\n",
        "        'Mewani': 'Indian politician Jignesh Mevani',\n",
        "        'clichéd': 'cliché',\n",
        "        'cliché(s|)': 'cliché',\n",
        "        'Wjy': 'Why',\n",
        "        'Fadnavis': 'Indian politician Devendra Fadnavis',\n",
        "        'Awadesh': 'Indian engineer Awdhesh Singh',\n",
        "        'Awdhesh': 'Indian engineer Awdhesh Singh',\n",
        "        'Khalistanis': 'Sikh separatist movement',\n",
        "        'madheshi': 'Madheshi',\n",
        "        'Quorans': 'Quoran',\n",
        "        'BNBR': 'Be Nice, Be Respectful',\n",
        "        'Bolsonaro': 'Jair Bolsonaro',\n",
        "        'XXXTentacion': 'Tentacion',\n",
        "        'Padmavat': 'Indian Movie Padmaavat',\n",
        "        'Žižek': 'Slovenian philosopher Slavoj Žižek',\n",
        "        'Adityanath': 'Indian monk Yogi Adityanath',\n",
        "        '(B|b)rexit': 'British Exit',\n",
        "        'jallikattu': 'Jallikattu',\n",
        "        'fortnite': 'Fortnite',\n",
        "        'Swachh': 'Swachh Bharat mission campaign',\n",
        "        'Qoura': 'Quora',\n",
        "        'narcissit': 'narcissist',\n",
        "        # extra in sample\n",
        "        'Doklam': 'Tibet',\n",
        "        'Drumpf': 'Donald Trump',\n",
        "        'Strzok': 'Hillary Clinton scandal',\n",
        "        'rohingya': 'Rohingya',\n",
        "        'wumao': 'offensive Chinese',\n",
        "        'Sanghis': 'Sanghi',\n",
        "        'Tamilans': 'Tamils',\n",
        "        'biharis': 'Biharis',\n",
        "        'Rejuvalex': 'hair growth formula',\n",
        "        'Feku': 'The Man of India',\n",
        "        'deplorables': 'deplorable',\n",
        "        'muhajirs': 'Muslim immigrants',\n",
        "        'Brexiters': 'British Exit supporters',\n",
        "        'Brexiteers': 'British Exit supporters',\n",
        "        'Brexiting': 'British Exit',\n",
        "        'Gujratis': 'Gujarati',\n",
        "        'Chutiya': 'Tibet people',\n",
        "        'thighing': 'masturbate',\n",
        "        '卐': 'Nazi Germany',\n",
        "        'rohingyas': 'Muslim ethnic group',\n",
        "        'Pribumi': 'Native Indonesians',\n",
        "        'Gurmehar': 'Gurmehar Kaur Indian student activist',\n",
        "        'Novichok': 'Soviet Union agents',\n",
        "        'Khazari': 'Khazars',\n",
        "        'Demonetization': 'demonetization',\n",
        "        'demonetisation': 'demonetization',\n",
        "        'cryptocurrencies': 'bitcoin',\n",
        "        'Hindians': 'offensive Indian',\n",
        "        'vaxxers': 'vocal nationalists',\n",
        "        'remoaners': 'remainer',\n",
        "        'Jewism': 'Judaism',\n",
        "        'Eroupian': 'European',\n",
        "        'WMAF': 'White male Asian female',\n",
        "        'moeslim': 'Muslim',\n",
        "        'cishet': 'cisgender and heterosexual person',\n",
        "        'Eurocentrics': 'Eurocentrism',\n",
        "        'Jewdar': 'Jew dar',\n",
        "        'Asifas': 'abduction, rape, murder case',\n",
        "        'marathis': 'Marathi',\n",
        "        'Trumpanzees': 'Trump chimpanzee',\n",
        "        'quoras': 'Quora',\n",
        "        'Crimeans': 'Crimea people',\n",
        "        'atrracted': 'attract',\n",
        "        'LGBT': 'lesbian, gay, bisexual, transgender',\n",
        "        'Boshniaks': 'Bosniaks',\n",
        "        'Myeshia': 'widow of Green Beret killed in Niger',\n",
        "        'demcoratic': 'Democratic',\n",
        "        'raaping': 'rape',\n",
        "        'Dönmeh': 'Islam',\n",
        "        'feminazism': 'feminism nazi',\n",
        "        'Quroa': 'Quora',\n",
        "        'QUORA': 'Quora',\n",
        "        'langague': 'language',\n",
        "        '(H|h)ongkongese': 'HongKong people',\n",
        "        '(K|k)ashmirians': 'Kashmirian',\n",
        "        '(C|c)hodu': 'fucker',\n",
        "        'penish': 'penis',\n",
        "        'micropenis': 'small penis',\n",
        "        'Madridiots': 'Madrid idiot',\n",
        "        'Ambedkarites': 'Dalit Buddhist movement',\n",
        "        'ReleaseTheMemo': 'cry for the right and Trump supporters',\n",
        "        'harrase': 'harass',\n",
        "        '(B|b)arracoon': 'Black slave',\n",
        "        '(C|c)astrater': 'castration',\n",
        "        '(R|r)apistan': 'rapist Pakistan',\n",
        "        '(T|t)urkified': 'Turkification',\n",
        "        'Dumbassistan': 'dumb ass Pakistan',\n",
        "        'facetards': 'Facebook retards',\n",
        "        'rapefugees': 'rapist refugee',\n",
        "        'superficious': 'superficial',\n",
        "        # extra from kagglers\n",
        "        'colour': 'color',\n",
        "        'centre': 'center',\n",
        "        'favourite': 'favorite',\n",
        "        'travelling': 'traveling',\n",
        "        'counselling': 'counseling',\n",
        "        'theatre': 'theater',\n",
        "        'cancelled': 'canceled',\n",
        "        'labour': 'labor',\n",
        "        'organisation': 'organization',\n",
        "        'wwii': 'world war 2',\n",
        "        'citicise': 'criticize',\n",
        "        'youtu ': 'youtube ',\n",
        "        'Qoura': 'Quora',\n",
        "        'sallary': 'salary',\n",
        "        'Whta': 'What',\n",
        "        'narcisist': 'narcissist',\n",
        "        'narcissit': 'narcissist',\n",
        "        'howdo': 'how do',\n",
        "        'whatare': 'what are',\n",
        "        'howcan': 'how can',\n",
        "        'howmuch': 'how much',\n",
        "        'howmany': 'how many',\n",
        "        'whydo': 'why do',\n",
        "        'doI': 'do I',\n",
        "        'theBest': 'the best',\n",
        "        'howdoes': 'how does',\n",
        "        'mastrubation': 'masturbation',\n",
        "        'mastrubate': 'masturbate',\n",
        "        'mastrubating': 'masturbating',\n",
        "        'pennis': 'penis',\n",
        "        'Etherium': 'Ethereum',\n",
        "        'bigdata': 'big data',\n",
        "        '2k17': '2017',\n",
        "        '2k18': '2018',\n",
        "        'qouta': 'quota',\n",
        "        'exboyfriend': 'ex boyfriend',\n",
        "        'airhostess': 'air hostess',\n",
        "        'whst': 'what',\n",
        "        'watsapp': 'whatsapp',\n",
        "        'demonitisation': 'demonetization',\n",
        "        'demonitization': 'demonetization',\n",
        "        'demonetisation': 'demonetization'\n",
        "    }\n",
        "    misspell_re = re.compile('(%s)' % '|'.join(misspell_to_sub.keys()))\n",
        "\n",
        "    def _replace(match):\n",
        "        \n",
        "        \"\"\"\n",
        "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
        "        \"\"\"\n",
        "        return misspell_to_sub.get(match.group(0), match.group(0))\n",
        "    return misspell_re.sub(_replace, text)\n",
        "\n",
        "def spacing_misspell(text):\n",
        "    \"\"\"\n",
        "    'deadbody' -> 'dead body'\n",
        "    \"\"\"\n",
        "    misspell_list = [\n",
        "        'body',\n",
        "        '(D|d)ead',\n",
        "        '(N|n)orth',\n",
        "        '(K|k)orea',\n",
        "        'matrix',\n",
        "        '(S|s)hit',\n",
        "        '(F|f)uck',\n",
        "        '(F|f)uk',\n",
        "        '(F|f)ck',\n",
        "        '(D|d)ick',\n",
        "        'Trump',\n",
        "        '\\W(A|a)nti',\n",
        "        '(W|w)hy',\n",
        "        # 'Jew',\n",
        "        'bait',\n",
        "        'care',\n",
        "        'troll',\n",
        "        'over',\n",
        "        'gender',\n",
        "        'people',\n",
        "        'kind',\n",
        "        '(S|s)ick',\n",
        "        '(S|s)uck',\n",
        "        '(I|i)diot',\n",
        "        # 'hole(s|)\\W',\n",
        "        '(B|b)ooty',\n",
        "        '(C|c)oin(s|)\\W',\n",
        "        '\\W(N|n)igger'\n",
        "    ]\n",
        "    misspell_re = re.compile('(%s)' % '|'.join(misspell_list))\n",
        "    return misspell_re.sub(r\" \\1 \", text)\n",
        "\n",
        "\n",
        "def clean_latex(text):\n",
        "    \"\"\"\n",
        "    convert r\"[math]\\vec{x} + \\vec{y}\" to English\n",
        "    \"\"\"\n",
        "    # edge case\n",
        "    text = re.sub(r'\\[math\\]', ' LaTex math ', text)\n",
        "    text = re.sub(r'\\[\\/math\\]', ' LaTex math ', text)\n",
        "    text = re.sub(r'\\\\', ' LaTex ', text)\n",
        "\n",
        "    pattern_to_sub = {\n",
        "        r'\\\\mathrm': ' LaTex math mode ',\n",
        "        r'\\\\mathbb': ' LaTex math mode ',\n",
        "        r'\\\\boxed': ' LaTex equation ',\n",
        "        r'\\\\begin': ' LaTex equation ',\n",
        "        r'\\\\end': ' LaTex equation ',\n",
        "        r'\\\\left': ' LaTex equation ',\n",
        "        r'\\\\right': ' LaTex equation ',\n",
        "        r'\\\\(over|under)brace': ' LaTex equation ',\n",
        "        r'\\\\text': ' LaTex equation ',\n",
        "        r'\\\\vec': ' vector ',\n",
        "        r'\\\\var': ' variable ',\n",
        "        r'\\\\theta': ' theta ',\n",
        "        r'\\\\mu': ' average ',\n",
        "        r'\\\\min': ' minimum ',\n",
        "        r'\\\\max': ' maximum ',\n",
        "        r'\\\\sum': ' + ',\n",
        "        r'\\\\times': ' * ',\n",
        "        r'\\\\cdot': ' * ',\n",
        "        r'\\\\hat': ' ^ ',\n",
        "        r'\\\\frac': ' / ',\n",
        "        r'\\\\div': ' / ',\n",
        "        r'\\\\sin': ' Sine ',\n",
        "        r'\\\\cos': ' Cosine ',\n",
        "        r'\\\\tan': ' Tangent ',\n",
        "        r'\\\\infty': ' infinity ',\n",
        "        r'\\\\int': ' integer ',\n",
        "        r'\\\\in': ' in ',\n",
        "    }\n",
        "    # post process for look up\n",
        "    pattern_dict = {k.strip('\\\\'): v for k, v in pattern_to_sub.items()}\n",
        "    # init re\n",
        "    patterns = pattern_to_sub.keys()\n",
        "    pattern_re = re.compile('(%s)' % '|'.join(patterns))\n",
        "\n",
        "    def _replace(match):\n",
        "        \"\"\"\n",
        "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
        "        \"\"\"\n",
        "        return pattern_dict.get(match.group(0).strip('\\\\'), match.group(0))\n",
        "    return pattern_re.sub(_replace, text)\n",
        "\n",
        "\n",
        "def normalize_unicode(text):\n",
        "    \"\"\"\n",
        "    unicode string normalization\n",
        "    \"\"\"\n",
        "    return unicodedata.normalize('NFKD', text)\n",
        "\n",
        "\n",
        "def remove_newline(text):\n",
        "    \"\"\"\n",
        "    remove \\n and  \\t\n",
        "    \"\"\"\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\t', ' ', text)\n",
        "    text = re.sub('\\b', ' ', text)\n",
        "    text = re.sub('\\r', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def decontracted(text):\n",
        "    \"\"\"\n",
        "    de-contract the contraction\n",
        "    \"\"\"\n",
        "    # specific\n",
        "    text = re.sub(r\"(W|w)on(\\'|\\’)t\", \"will not\", text)\n",
        "    text = re.sub(r\"(C|c)an(\\'|\\’)t\", \"can not\", text)\n",
        "    text = re.sub(r\"(Y|y)(\\'|\\’)all\", \"you all\", text)\n",
        "    text = re.sub(r\"(Y|y)a(\\'|\\’)ll\", \"you all\", text)\n",
        "\n",
        "    # general\n",
        "    text = re.sub(r\"(I|i)(\\'|\\’)m\", \"i am\", text)\n",
        "    text = re.sub(r\"(A|a)in(\\'|\\’)t\", \"is not\", text)\n",
        "    text = re.sub(r\"n(\\'|\\’)t\", \" not\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)re\", \" are\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)s\", \" is\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)d\", \" would\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)ll\", \" will\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)t\", \" not\", text)\n",
        "    text = re.sub(r\"(\\'|\\’)ve\", \" have\", text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def spacing_punctuation(text):\n",
        "    \"\"\"\n",
        "    add space before and after punctuation and symbols\n",
        "    \"\"\"\n",
        "    regular_punct = list(string.punctuation)\n",
        "    extra_punct = [\n",
        "        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&',\n",
        "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
        "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
        "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
        "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
        "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
        "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
        "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
        "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
        "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
        "    all_punct = ''.join(sorted(list(set(regular_punct + extra_punct))))\n",
        "    re_tok = re.compile(f'([{all_punct}])')\n",
        "    return re_tok.sub(r' \\1 ', text)\n",
        "\n",
        "\n",
        "def spacing_digit(text):\n",
        "    \"\"\"\n",
        "    add space before and after digits\n",
        "    \"\"\"\n",
        "    re_tok = re.compile('([0-9])')\n",
        "    return re_tok.sub(r' \\1 ', text)\n",
        "\n",
        "\n",
        "def spacing_number(text):\n",
        "    \"\"\"\n",
        "    add space before and after numbers\n",
        "    \"\"\"\n",
        "    re_tok = re.compile('([0-9]{1,})')\n",
        "    return re_tok.sub(r' \\1 ', text)\n",
        "\n",
        "\n",
        "def remove_number(text):\n",
        "    \"\"\"\n",
        "    numbers are not toxic\n",
        "    \"\"\"\n",
        "    return re.sub('\\d+', ' ', text)\n",
        "\n",
        "\n",
        "def remove_space(text):\n",
        "    \"\"\"\n",
        "    remove extra spaces and ending space if any\n",
        "    \"\"\"\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = re.sub('\\s+$', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "tokenizer\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def preprocess(text, remove_num=True):\n",
        "    \"\"\"\n",
        "    preprocess text into clean text for tokenization\n",
        "    NOTE:\n",
        "        1. glove supports uppper case words\n",
        "        2. glove supports digit\n",
        "        3. glove supports punctuation\n",
        "        5. glove supports domains e.g. www.apple.com\n",
        "        6. glove supports misspelled words e.g. FUCKKK\n",
        "    \"\"\"\n",
        "    # # 1. normalize\n",
        "    text = normalize_unicode(text)\n",
        "    # # 2. remove new line\n",
        "    text = remove_newline(text)\n",
        "    # 3. de-contract\n",
        "    text = decontracted(text)\n",
        "    # 4. clean misspell\n",
        "    text = clean_misspell(text)\n",
        "    # 5. space misspell\n",
        "    #text = spacing_misspell(text)\n",
        "    # 6. clean_latex\n",
        "    text = clean_latex(text)\n",
        "    # 7. space\n",
        "    text = spacing_punctuation(text)\n",
        "    # 8. handle number\n",
        "    if remove_num:\n",
        "        text = remove_number(text)\n",
        "    else:\n",
        "        text = spacing_digit(text)\n",
        "    # 9. remove space\n",
        "    text = remove_space(text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do77vFhrDS7V",
        "colab_type": "code",
        "outputId": "26fae143-952f-424f-91df-aa8cdd21da00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[\"question_text\"] = df[\"question_text\"].progress_apply(preprocess)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1306122/1306122 [04:49<00:00, 4510.91it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htWYDzWJ-vn5",
        "colab_type": "code",
        "outputId": "9a039478-ea82-47ae-cf38-66302510518c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_words = len(vocab)+1\n",
        "del vocab\n",
        "emb_file = \"glove.840B.300d/glove.840B.300d.txt\"\n",
        "glove_dic = {}\n",
        "for line in tqdm_notebook(open(emb_file)):\n",
        "    temp = line.split(\" \")\n",
        "    glove_dic[temp[0]] = np.asarray(temp[1:],dtype='float32')\n",
        "\n",
        "train, val = train_test_split(df, test_size=0.1)\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=n_words)\n",
        "tokenizer.fit_on_texts(list(train.question_text))\n",
        "\n",
        "q_train = tokenizer.texts_to_sequences(train.question_text)\n",
        "q_val = tokenizer.texts_to_sequences(val.question_text)\n",
        "\n",
        "max_len = 65\n",
        "q_train = pad_sequences(q_train,maxlen=max_len)\n",
        "q_val = pad_sequences(q_val,maxlen=max_len)\n",
        "\n",
        "y_train = train.target\n",
        "y_val = val.target\n",
        "\n",
        "del train,val\n",
        "word_index = tokenizer.word_index\n",
        "emb_size = glove_dic['.'].shape[0]\n",
        "emb_matrix = np.zeros((n_words,emb_size))\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        \n",
        "        continue\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "    w = w.lower()\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "    w = w.upper()\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "\n",
        "    w = w.capitalize()\n",
        "    vec = glove_dic.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix[index,:] = vec\n",
        "        continue\n",
        "        "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "194eabb51e3f439ab6a29c88105b5f2a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJafHcxoslu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open('models/tokenizer.pickle','wb') as handle:\n",
        "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9omzsQ4jO-h",
        "colab_type": "code",
        "outputId": "29b5d154-1c09-4091-c795-941eaf31ccf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "del glove_dic\n",
        "emb_file_par=\"paragram_300_sl999/paragram_300_sl999.txt\"\n",
        "glove_dic1 = {}\n",
        "emb_matrix_par = np.zeros((n_words,emb_size))\n",
        "for line in tqdm_notebook(open(emb_file_par,encoding=\"utf8\", errors='ignore')):\n",
        "    temp = line.split(\" \")\n",
        "    glove_dic1[temp[0]] = np.asarray(temp[1:],dtype='float32')\n",
        "for w,index in word_index.items():\n",
        "    if index >= n_words:\n",
        "        \n",
        "        continue\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "    w = w.lower()\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "    w = w.upper()\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "\n",
        "    w = w.capitalize()\n",
        "    vec = glove_dic1.get(w)\n",
        "    if vec is not None:\n",
        "        \n",
        "        emb_matrix_par[index,:] = vec\n",
        "        continue\n",
        "del glove_dic1\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8fee632a2fc4a5fbb4a4ee51c572ef9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL_NFXjFlClV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix_com = np.concatenate((emb_matrix, emb_matrix_par), axis=1)\n",
        "del emb_matrix\n",
        "del emb_matrix_par"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iFHOktvEFuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "#find the best threshold\n",
        "def optim_thres(y_val,y_pred):\n",
        "    score = 0\n",
        "    thresholds = np.arange(0.1,0.501,0.01)\n",
        "    for thres in thresholds:\n",
        "        thres = np.round(thres,2)\n",
        "        temp_pred = (y_pred > thres).astype(int)\n",
        "        temp_score = f1_score(y_val,temp_pred)\n",
        "        print(\"Thres: {} --------- F1: {}\".format(thres,temp_score))\n",
        "        if temp_score > score:\n",
        "            score = temp_score\n",
        "            final_thres = thres\n",
        "    return final_thres"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPosRrOgl6vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim=65,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "        \n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        \n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z60udXehmcuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb_size=600"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2sZcnC_yshV",
        "colab_type": "code",
        "outputId": "0dba3549-0803-4e87-aa53-31e929f7a1f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        }
      },
      "source": [
        "inp = Input(shape=(max_len,))\n",
        "x = Embedding(input_dim=n_words,output_dim=emb_size, weights=[embedding_matrix_com])(inp)\n",
        "x = SpatialDropout1D(.4,seed=1029)(x)\n",
        "x = Bidirectional(CuDNNLSTM(150, return_sequences=True))(x)\n",
        "x =  Bidirectional(CuDNNGRU(150,return_sequences=True))(x)\n",
        "x = Attention(step_dim=max_len)(x)\n",
        "x = Dense(36,activation='relu')(x)\n",
        "x = Dropout(0.1)(x)\n",
        "x = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=inp,output=x)\n",
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0730 17:16:32.026632 139910359783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0730 17:16:32.089023 139910359783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0730 17:16:32.117395 139910359783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0730 17:16:32.132949 139910359783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0730 17:16:32.133827 139910359783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0730 17:16:38.538084 139910359783296 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 65)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 65, 600)           305294400 \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 65, 600)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 65, 300)           902400    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 65, 300)           406800    \n",
            "_________________________________________________________________\n",
            "attention_1 (Attention)      (None, 300)               365       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 36)                10836     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 36)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 37        \n",
            "=================================================================\n",
            "Total params: 306,614,838\n",
            "Trainable params: 306,614,838\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfhBWlj7TRsE",
        "colab_type": "code",
        "outputId": "85ffbaae-7a51-4595-f6be-376b71588491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "model_name = 'trained'\n",
        "checkpoint = ModelCheckpoint(filepath='models/trainedModel.h5'.format(model_name),\n",
        "                             monitor='val_f1',mode='max',verbose=1,\n",
        "                            save_best_only=True)\n",
        "\n",
        "adamax= Adamax(lr=0.003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.000002)\n",
        "model.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['acc',f1])\n",
        "model.fit(q_train,y_train,batch_size=2500,epochs=7,validation_data=(q_val,y_val),verbose=1,callbacks=[checkpoint])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0730 17:16:40.659801 139910359783296 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0730 17:16:40.683340 139910359783296 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 305294400 elements. This may consume a large amount of memory.\n",
            "  num_elements)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1175509 samples, validate on 130613 samples\n",
            "Epoch 1/7\n",
            "1175509/1175509 [==============================] - 414s 352us/step - loss: 0.1276 - acc: 0.9507 - f1: 0.5235 - val_loss: 0.1039 - val_acc: 0.9579 - val_f1: 0.6169\n",
            "\n",
            "Epoch 00001: val_f1 improved from -inf to 0.61686, saving model to models/trainedModel.h5\n",
            "Epoch 2/7\n",
            "1175509/1175509 [==============================] - 406s 346us/step - loss: 0.1065 - acc: 0.9575 - f1: 0.6189 - val_loss: 0.0990 - val_acc: 0.9602 - val_f1: 0.6605\n",
            "\n",
            "Epoch 00002: val_f1 improved from 0.61686 to 0.66049, saving model to models/trainedModel.h5\n",
            "Epoch 3/7\n",
            "1175509/1175509 [==============================] - 406s 346us/step - loss: 0.1009 - acc: 0.9597 - f1: 0.6436 - val_loss: 0.0961 - val_acc: 0.9612 - val_f1: 0.6598\n",
            "\n",
            "Epoch 00003: val_f1 did not improve from 0.66049\n",
            "Epoch 4/7\n",
            "1175509/1175509 [==============================] - 405s 345us/step - loss: 0.0968 - acc: 0.9612 - f1: 0.6630 - val_loss: 0.0941 - val_acc: 0.9619 - val_f1: 0.6638\n",
            "\n",
            "Epoch 00004: val_f1 improved from 0.66049 to 0.66378, saving model to models/trainedModel.h5\n",
            "Epoch 5/7\n",
            "1175509/1175509 [==============================] - 406s 346us/step - loss: 0.0934 - acc: 0.9625 - f1: 0.6770 - val_loss: 0.0932 - val_acc: 0.9622 - val_f1: 0.6743\n",
            "\n",
            "Epoch 00005: val_f1 improved from 0.66378 to 0.67426, saving model to models/trainedModel.h5\n",
            "Epoch 6/7\n",
            "1175509/1175509 [==============================] - 406s 346us/step - loss: 0.0902 - acc: 0.9638 - f1: 0.6915 - val_loss: 0.0932 - val_acc: 0.9623 - val_f1: 0.6843\n",
            "\n",
            "Epoch 00006: val_f1 improved from 0.67426 to 0.68433, saving model to models/trainedModel.h5\n",
            "Epoch 7/7\n",
            "1175509/1175509 [==============================] - 406s 346us/step - loss: 0.0871 - acc: 0.9648 - f1: 0.7027 - val_loss: 0.0931 - val_acc: 0.9621 - val_f1: 0.6827\n",
            "\n",
            "Epoch 00007: val_f1 did not improve from 0.68433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3f070d0860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0tHSHGQgTT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=model.predict(q_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9aAvu2OUzkk",
        "colab_type": "code",
        "outputId": "fd90e4b0-c9e0-4243-9752-977c1814a7dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "optim_thres(y_val,y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thres: 0.1 --------- F1: 0.5953846798173974\n",
            "Thres: 0.11 --------- F1: 0.6031868084924601\n",
            "Thres: 0.12 --------- F1: 0.6117524066733457\n",
            "Thres: 0.13 --------- F1: 0.6188217562835232\n",
            "Thres: 0.14 --------- F1: 0.6265331890331891\n",
            "Thres: 0.15 --------- F1: 0.6318341949947385\n",
            "Thres: 0.16 --------- F1: 0.6377283078496073\n",
            "Thres: 0.17 --------- F1: 0.6418043979846494\n",
            "Thres: 0.18 --------- F1: 0.6457638425617078\n",
            "Thres: 0.19 --------- F1: 0.6501183174771816\n",
            "Thres: 0.2 --------- F1: 0.6539213768824566\n",
            "Thres: 0.21 --------- F1: 0.6575871632329635\n",
            "Thres: 0.22 --------- F1: 0.6612273500850936\n",
            "Thres: 0.23 --------- F1: 0.6639364983062844\n",
            "Thres: 0.24 --------- F1: 0.6653050804186879\n",
            "Thres: 0.25 --------- F1: 0.6680410245838273\n",
            "Thres: 0.26 --------- F1: 0.671350507416081\n",
            "Thres: 0.27 --------- F1: 0.6735380732015145\n",
            "Thres: 0.28 --------- F1: 0.6757632067958589\n",
            "Thres: 0.29 --------- F1: 0.6771485106155409\n",
            "Thres: 0.3 --------- F1: 0.6797710335889405\n",
            "Thres: 0.31 --------- F1: 0.6804798255179935\n",
            "Thres: 0.32 --------- F1: 0.6824227767395844\n",
            "Thres: 0.33 --------- F1: 0.683883839503436\n",
            "Thres: 0.34 --------- F1: 0.6839783324956721\n",
            "Thres: 0.35 --------- F1: 0.6853249239779254\n",
            "Thres: 0.36 --------- F1: 0.6879118382185867\n",
            "Thres: 0.37 --------- F1: 0.6882521489971347\n",
            "Thres: 0.38 --------- F1: 0.688507540301612\n",
            "Thres: 0.39 --------- F1: 0.6883699260380874\n",
            "Thres: 0.4 --------- F1: 0.6888980214877003\n",
            "Thres: 0.41 --------- F1: 0.689500147885241\n",
            "Thres: 0.42 --------- F1: 0.6903426047511042\n",
            "Thres: 0.43 --------- F1: 0.689086752496691\n",
            "Thres: 0.44 --------- F1: 0.6885385081867799\n",
            "Thres: 0.45 --------- F1: 0.6886671156554215\n",
            "Thres: 0.46 --------- F1: 0.688190629051176\n",
            "Thres: 0.47 --------- F1: 0.6881305268402043\n",
            "Thres: 0.48 --------- F1: 0.6872683876640915\n",
            "Thres: 0.49 --------- F1: 0.684957546572044\n",
            "Thres: 0.5 --------- F1: 0.6827987964919019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.42"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}